{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ticker = 'seekingalpha-JCAP-2016-Q2'\n",
    "interval = 0.1 # In seconds.\n",
    "maxNumIntervals = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import gensim\n",
    "import numpy as np\n",
    "from aubio import pitch\n",
    "import scipy.io.wavfile as wav\n",
    "from python_speech_features import mfcc\n",
    "from python_speech_features import delta\n",
    "from python_speech_features import ssc"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Load pre-trained Word2Vec embeddings from Google.\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('embedding/vectors.bin', binary = True)\n",
    "wordVecD = model.word_vec('test').shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extraction settings.\n",
    "intervalMS = interval * 1000\n",
    "tInterval = 0.01 # In seconds.\n",
    "intRatio = tInterval / interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "def iSplit(iterable, splitters):\n",
    "    return [list(g) for k, g in itertools.groupby(iterable, lambda x: x in splitters) if not k]\n",
    "\n",
    "tFile = open('data/transcripts/' + ticker + '.txt')\n",
    "tString = tFile.read() # To be chunked.\n",
    "transcript = tString.split('\\n')[:-2]\n",
    "transcript = iSplit(transcript, ('<EOS>'))\n",
    "\n",
    "# Helper function below.\n",
    "def SLToTuple(splitSent):\n",
    "    return [(int(word.split(':')[0]), int(word.split(':')[1]), word.split(' ')[1]) for word in splitSent]\n",
    "transcript = [SLToTuple(sentence) for sentence in transcript]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "intervals = [(sentence[-1][0] + sentence[-1][1] - sentence[0][0], sentence) for sentence in transcript]\n",
    "intIndices = [int(math.ceil((transcript[i][-1][0] + transcript[i][-1][1]) * intRatio)) for i in range(len(transcript) - 1)]\n",
    "intIndicesFine = [(transcript[i][-1][0] + transcript[i][-1][1]) * 10 for i in range(len(transcript) - 1)]\n",
    "# maxNumIntervals = int(math.ceil(max(intervals)[0] * interval))\n",
    "numSentences = len(transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(rate, signal) = wav.read('data/audio/' + ticker + '.wav')\n",
    "signal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 400 is a magic number here to make things work out nicely.\n",
    "pitchesPerInterval = int(interval / (400.0 / rate))\n",
    "pitchComp = pitch('default', 4096, 400, rate)\n",
    "numPitchOutputs = len(signal) // 400\n",
    "rawPitches = np.zeros((numPitchOutputs))\n",
    "\n",
    "# Iteratively compute all pitches.\n",
    "for i in range(numPitchOutputs):\n",
    "    start, end = i * 400, (i + 1) * 400\n",
    "    rawPitches[i] = pitchComp(signal[start:end].astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawPitches = rawPitches[:len(rawPitches) - len(rawPitches) % pitchesPerInterval]\n",
    "rawPitches = np.mean(np.reshape(rawPitches, (-1, pitchesPerInterval)), axis = 1)\n",
    "rawPitches = np.expand_dims(rawPitches, axis = 1)\n",
    "rawPitches.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "squish = int(interval / 0.025)\n",
    "rawMFCC = mfcc(signal, rate, winstep = 0.025)\n",
    "rawMFCCDelta = delta(rawMFCC, 2) # 2 from internet.\n",
    "rawMFCCDD = delta(rawMFCCDelta, 2) # 2 from internet.\n",
    "rawSSC = ssc(signal, rate, winstep = 0.025)\n",
    "\n",
    "# Truncate trailing readings to interval.\n",
    "rawMFCC = rawMFCC[:len(rawMFCC) - len(rawMFCC) % squish]\n",
    "rawMFCCDelta = rawMFCCDelta[:len(rawMFCCDelta) - len(rawMFCCDelta) % squish]\n",
    "rawMFCCDD = rawMFCCDD[:len(rawMFCCDD) - len(rawMFCCDD) % squish]\n",
    "rawSSC = rawSSC[:len(rawSSC) - len(rawSSC) % squish]\n",
    "\n",
    "# Reshape to average every squish values.\n",
    "rawMFCC = np.reshape(rawMFCC, (-1, squish, 13))\n",
    "rawMFCCDelta = np.reshape(rawMFCCDelta, (-1, squish, 13))\n",
    "rawMFCCDD = np.reshape(rawMFCCDD, (-1, squish, 13))\n",
    "rawSSC = np.reshape(rawSSC, (-1, squish, 26))\n",
    "\n",
    "# Reduce sum along squish axis.\n",
    "rawMFCC = np.mean(rawMFCC, axis = 1)\n",
    "rawMFCCDelta = np.mean(rawMFCCDelta, axis = 1)\n",
    "rawMFCCDD = np.mean(rawMFCCDD, axis = 1)\n",
    "rawSSC = np.mean(rawSSC, axis = 1)\n",
    "\n",
    "# Diagnostic check of shapes.\n",
    "rawMFCC.shape, rawMFCCDelta.shape, rawMFCCDD.shape, rawSSC.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numIntervals = np.zeros((numSentences), dtype = int)\n",
    "MFCC = np.zeros((numSentences, maxNumIntervals, rawMFCC.shape[1]))\n",
    "Pitches = np.zeros((numSentences, maxNumIntervals, rawPitches.shape[1]))\n",
    "MFCCDelta = np.zeros((numSentences, maxNumIntervals, rawMFCCDelta.shape[1]))\n",
    "MFCCDD = np.zeros((numSentences, maxNumIntervals, rawMFCCDD.shape[1]))\n",
    "SSC = np.zeros((numSentences, maxNumIntervals, rawSSC.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MFCCList = np.split(rawMFCC, intIndices)\n",
    "PitchesList = np.split(rawPitches, intIndices)\n",
    "MFCCDeltaList = np.split(rawMFCCDelta, intIndices)\n",
    "MFCCDDList = np.split(rawMFCCDD, intIndices)\n",
    "SSCList = np.split(rawSSC, intIndices)\n",
    "\n",
    "# Chunk MFCC/SSC by sentence.\n",
    "for i in range(len(MFCCList)):\n",
    "    sentMFCC = MFCCList[i]\n",
    "    sentPitches = PitchesList[i]\n",
    "    sentMFCCDD = MFCCDDList[i]\n",
    "    sentMFCCDelta = MFCCDeltaList[i]\n",
    "    sentSSC = SSCList[i]\n",
    "\n",
    "    # Pad to avoid spooky off-by-one bugs.\n",
    "    intervals = min(sentMFCC.shape[0], maxNumIntervals)\n",
    "    if len(sentPitches) < intervals: # TODO: Find a better way to do this.\n",
    "        sentPitches = np.pad(sentPitches, ((0, intervals - len(sentPitches)), (0, 0)), mode = 'mean')\n",
    "\n",
    "    # Zeros here will be masked by an RNN layer.\n",
    "    MFCC[i, :intervals, :] = sentMFCC[:intervals, :]\n",
    "    Pitches[i, :intervals, :] = sentPitches[:intervals, :]\n",
    "    MFCCDelta[i, :intervals, :] = sentMFCCDelta[:intervals, :]\n",
    "    MFCCDD[i, :intervals, :] = sentMFCCDD[:intervals, :]\n",
    "    SSC[i, :intervals, :] = sentSSC[:intervals, :]\n",
    "\n",
    "    # Really a by-product.\n",
    "    numIntervals[i] = intervals"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "wordVecs = np.zeros((numSentences, maxNumIntervals, wordVecD))\n",
    "wordVecs[:, :] = model.word_vec('UNK')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Adds one word vector to word vectors.\n",
    "def placeWord(sentIdx, interval, word):\n",
    "    # print(sentIdx, interval, word)\n",
    "    try: wordVecs[sentIdx, interval, :] = model.word_vec(word)\n",
    "    except KeyError: wordVecs[sentIdx, interval, :] = model.word_vec('UNK')\n",
    "    except ValueError: return\n",
    "\n",
    "# Place words in wordVecs.\n",
    "for i in range(numSentences):\n",
    "    sentence = transcript[i]\n",
    "    currInterval = 0\n",
    "    for word in sentence:\n",
    "        # Check for discrepancies.\n",
    "        wordStart = word[0] * intRatio\n",
    "        wordTime = word[1] * intRatio\n",
    "        start = int(math.ceil(wordStart))\n",
    "        end = int(math.ceil(wordStart + wordTime))\n",
    "        for j in range(currInterval, currInterval + int(end - start)):\n",
    "            placeWord(i, j, word[2])\n",
    "        currInterval += end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MFCC.shape, MFCCDelta.shape, MFCCDD.shape, SSC.shape, Pitches.shape, numIntervals.shape, len(intIndices), len(intIndicesFine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('features/MFCC-' + ticker, MFCC)\n",
    "np.save('features/Pitches-' + ticker, Pitches)\n",
    "np.save('features/MFCCDelta-' + ticker, MFCCDelta)\n",
    "np.save('features/MFCCDD-' + ticker, MFCCDD)\n",
    "np.save('features/SSC-' + ticker, SSC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# np.save('features/words-' + ticker, wordVecs)\n",
    "np.save('features/intervals-' + ticker, numIntervals)\n",
    "np.save('scratch/splits-' + ticker, np.array(intIndices))\n",
    "np.save('scratch/splits-fine-' + ticker, np.array(intIndicesFine))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
